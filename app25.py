import streamlit as st
import pandas as pd
# requestsã¨jsonã¯GASã‚’ä½¿ã‚ãªã„å ´åˆã¯ä¸è¦ã ãŒã€æ±Žç”¨æ€§ã®ãŸã‚æ®‹ã™
import requests
import json
import os
import random
from datetime import datetime, date
import io

# --- Supabase æŽ¥ç¶šã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ ---
# â˜…â˜…â˜… ã“ã®è¡ŒãŒã‚¨ãƒ©ãƒ¼ã®åŽŸå› ãªã®ã§ã€ã“ã“ãŒimportã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã®ãŒç›®æ¨™ â˜…â˜…â˜…
from st_supabase_connection import SupabaseConnection

# --- è¨­å®šé …ç›® ---
# GASã®URLã¨ã‚­ãƒ¼ã¯Supabaseç§»è¡Œã«ä¼´ã„ä¸è¦ã«ãªã‚‹ãŸã‚å‰Šé™¤
# GAS_WEBAPP_URL = "https://script.google.com/macros/s/AKfycbzIHdzvPWRgu3uyOb2A1rHQTvpxzU6sLKBm5Ybwt--ozxLFe0_i7nr071RjwjgdkaxGA/exec"
# GAS_API_KEY = "my_streamlit_secret_key_123"

# ãƒ˜ãƒƒãƒ€ãƒ¼å®šç¾©
VOCAB_HEADERS = ['ID', 'ç”¨èªž (Term)', 'èª¬æ˜Ž (Definition)', 'ä¾‹æ–‡ (Example)', 'ã‚«ãƒ†ã‚´ãƒª (Category)', 'å­¦ç¿’é€²æ— (Progress)']
TEST_RESULTS_HEADERS = ['Date', 'Category', 'TestType', 'Score', 'TotalQuestions', 'Details']

# --- Streamlit ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®é–‹å§‹ ---
st.set_page_config(layout="wide")
st.title("ãƒ“ã‚¸ãƒã‚¹ç”¨èªžé›†ãƒ“ãƒ«ãƒ€ãƒ¼")

# --- ãƒšãƒ¼ã‚¸é·ç§»é–¢æ•° ---
def go_to_page(page_name):
    st.session_state.current_page = page_name
    st.rerun()

# st.session_state ã®åˆæœŸåŒ–
if 'username' not in st.session_state:
    st.session_state.username = None
if 'current_page' not in st.session_state:
    st.session_state.current_page = "ç”¨èªžé›†" # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒšãƒ¼ã‚¸ã‚’ç”¨èªžé›†ã«å¤‰æ›´
if 'vocab_data_loaded' not in st.session_state: # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒ•ãƒ©ã‚°
    st.session_state.vocab_data_loaded = False
if 'test_mode' not in st.session_state:
    st.session_state.test_mode = {
        'active': False,
        'current_question_index': 0,
        'questions': [],
        'answers': [],
        'score': 0,
        'detailed_results': [],
        'selected_category': 'å…¨ã‚«ãƒ†ã‚´ãƒª',
        'question_count': 10,
        'test_type': 'term_to_def', # 'term_to_def' or 'example_to_term'
        'question_source': 'random_all' # 'random_all', 'learning_focus'
    }
if 'test_review_mode' not in st.session_state:
    st.session_state.test_review_mode = {
        'active': False,
        'review_index': 0,
        'results_to_review': []
    }
# df_vocab ã¨ df_test_results ã‚‚ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã§ç®¡ç†ã™ã‚‹
if 'df_vocab' not in st.session_state:
    st.session_state.df_vocab = pd.DataFrame(columns=VOCAB_HEADERS)
if 'df_test_results' not in st.session_state:
    st.session_state.df_test_results = pd.DataFrame(columns=TEST_RESULTS_HEADERS)


# --- Supabase æŽ¥ç¶šã®åˆæœŸåŒ– (st.secrets ã‹ã‚‰èªè¨¼æƒ…å ±ã‚’å–å¾—) ---
@st.cache_resource
def get_supabase_connection():
    # st.secrets ã‹ã‚‰å®‰å…¨ã«èªè¨¼æƒ…å ±ã‚’å–å¾—
    url = st.secrets.get("SUPABASE_URL")
    key = st.secrets.get("SUPABASE_KEY")

    if not url or not key:
        st.error("Supabaseã®èªè¨¼æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚Streamlit Cloudã®Secretsã¾ãŸã¯.streamlit/secrets.tomlã«SUPABASE_URLã¨SUPABASE_KEYã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        st.stop() # å‡¦ç†ã‚’åœæ­¢ã—ã¦ã‚¨ãƒ©ãƒ¼ã‚’è¡¨ç¤º

    return st.connection("supabase", type=SupabaseConnection, url=url, key=key)

supabase = get_supabase_connection()


# --- Supabaseã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹é–¢æ•° (GASç‰ˆã‹ã‚‰ã®å¤‰æ›´) ---
@st.cache_data(ttl=60)
def load_data_from_supabase(table_name):
    st.sidebar.write(f"DEBUG: Attempting to load data from Supabase table: {table_name}")
    try:
        # Supabaseã‹ã‚‰å…¨ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
        response = supabase.table(table_name).select("*").execute()
        
        if response.data:
            df = pd.DataFrame(response.data)
            st.sidebar.write(f"DEBUG: Successfully loaded {len(df)} rows from table '{table_name}'.")

            if table_name.startswith("vocab_"): # ç”¨èªžã‚·ãƒ¼ãƒˆã®å ´åˆ
                # å¿…è¦ãªã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã—ãªã„å ´åˆã«ä½œæˆï¼ˆã‚¤ãƒ³ãƒãƒ¼ãƒˆæ™‚ã®ã‚¨ãƒ©ãƒ¼å›žé¿ï¼‰
                for col in VOCAB_HEADERS:
                    if col not in df.columns:
                        df[col] = pd.NA
                df = df[VOCAB_HEADERS] # ã‚«ãƒ©ãƒ é †åºã‚’å›ºå®š
                
                df['ID'] = pd.to_numeric(df['ID'], errors='coerce').fillna(0).astype('Int64')
                df['å­¦ç¿’é€²æ— (Progress)'] = df['å­¦ç¿’é€²æ— (Progress)'].fillna('Not Started')
                df['ä¾‹æ–‡ (Example)'] = df['ä¾‹æ–‡ (Example)'].fillna('')
                df = df.dropna(subset=['ç”¨èªž (Term)', 'èª¬æ˜Ž (Definition)'], how='all') # ä¸¡æ–¹NaNã®è¡Œã‚’å‰Šé™¤
                df = df.drop_duplicates(subset=['ç”¨èªž (Term)', 'èª¬æ˜Ž (Definition)'], keep='first') # é‡è¤‡è¡Œã‚’å‰Šé™¤
                df = df.sort_values(by='ID').reset_index(drop=True)
                
            elif table_name.startswith("test_results_"): # ãƒ†ã‚¹ãƒˆçµæžœã‚·ãƒ¼ãƒˆã®å ´åˆ
                for col in TEST_RESULTS_HEADERS:
                    if col not in df.columns:
                        df[col] = pd.NA
                df = df[TEST_RESULTS_HEADERS]

                if 'Date' in df.columns:
                    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')
                    df = df.dropna(subset=['Date'])
                    if not df.empty:
                        df = df.sort_values(by='Date', ascending=False).reset_index(drop=True)
                
                if 'Details' in df.columns and not df.empty:
                    def parse_json_safely(json_str):
                        if pd.isna(json_str) or not isinstance(json_str, str) or not json_str.strip():
                            return []
                        try:
                            # Supabaseã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã¯æ—¢ã«è¾žæ›¸/ãƒªã‚¹ãƒˆã®å ´åˆã‚‚ã‚ã‚‹ãŸã‚ã€ç›´æŽ¥è¿”ã™
                            # æ–‡å­—åˆ—ã®å ´åˆã¯json.loadsã‚’è©¦ã¿ã‚‹
                            if isinstance(json_str, (dict, list)):
                                return json_str
                            return json.loads(json_str)
                        except (json.JSONDecodeError, TypeError):
                            st.warning(f"ãƒ†ã‚¹ãƒˆçµæžœã®è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚’JSONã¨ã—ã¦ãƒ‘ãƒ¼ã‚¹ã§ãã¾ã›ã‚“ã§ã—ãŸ: {str(json_str)[:200]}...")
                            return []
                    df['Details'] = df['Details'].apply(parse_json_safely)
                else:
                    df['Details'] = [[] for _ in range(len(df))]
            
            return df
        else:
            st.sidebar.write(f"DEBUG: No data found in table '{table_name}'. Returning empty DataFrame.")
            return pd.DataFrame(columns=TEST_RESULTS_HEADERS if table_name.startswith("test_results_") else VOCAB_HEADERS)

    except Exception as e:
        st.error(f"Supabaseã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        st.exception(e)
        st.sidebar.write(f"DEBUG: Supabase Read Error: {e}")
        return pd.DataFrame(columns=TEST_RESULTS_HEADERS if table_name.startswith("test_results_") else VOCAB_HEADERS)


# --- Supabaseã«ãƒ‡ãƒ¼ã‚¿ã‚’æ›¸ãè¾¼ã‚€é–¢æ•° (GASç‰ˆã‹ã‚‰ã®å¤‰æ›´) ---
def write_data_to_supabase(df, table_name):
    try:
        # Supabaseã«é€ã‚‹ãƒ‡ãƒ¼ã‚¿ã¯Pythonã®ãƒªã‚¹ãƒˆã‚ªãƒ–è¾žæ›¸å½¢å¼
        # Pandas DataFrameã‚’JSONå½¢å¼ã«å¤‰æ›ã™ã‚‹å‰ã«ã€DateTimeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ISOãƒ•ã‚©ãƒ¼ãƒžãƒƒãƒˆã«å¤‰æ›ã™ã‚‹å¿…è¦ãŒã‚ã‚‹
        data_to_upsert = df.to_dict(orient='records')
        
        # Detailsã‚«ãƒ©ãƒ ã®å‡¦ç†ï¼ˆSupabaseã¯JSONBåž‹ã§æ ¼ç´ã™ã‚‹ãŸã‚ã€ãã®ã¾ã¾Pythonã®ãƒªã‚¹ãƒˆ/è¾žæ›¸ã¨ã—ã¦æ¸¡ã™ï¼‰
        # to_dict(orient='records')ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã“ã‚Œã‚’é©åˆ‡ã«å‡¦ç†ã™ã‚‹ã¯ãš

        # Upsert (å­˜åœ¨ã™ã‚Œã°æ›´æ–°ã€ãªã‘ã‚Œã°æŒ¿å…¥) ã‚’ä½¿ç”¨
        # Supabaseã®ãƒ†ãƒ¼ãƒ–ãƒ«ã«ã¯ä¸»ã‚­ãƒ¼ï¼ˆé€šå¸¸ã¯IDï¼‰ãŒã‚ã‚‹ã“ã¨ã‚’å‰æã¨ã™ã‚‹
        # IDãŒè‡ªå‹•ç”Ÿæˆã®å ´åˆã¯ã€IDã‚’ç„¡è¦–ã—ã¦insertã™ã‚‹
        
        # ã¾ãšã¯æ—¢å­˜ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’ã™ã¹ã¦å‰Šé™¤ã—ã€æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’æŒ¿å…¥ã™ã‚‹æ–¹å¼ã§å®Ÿè£…
        # ã“ã‚Œã¯ãƒ‡ãƒ¼ã‚¿é‡ãŒå°‘ãªã„å ´åˆã«ã®ã¿é©ã—ã¦ãŠã‚Šã€å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§ã¯éžåŠ¹çŽ‡
        # ç†æƒ³çš„ã«ã¯ã€å¤‰æ›´ã•ã‚ŒãŸè¡Œã®ã¿ã‚’æ›´æ–°ã€å‰Šé™¤ã•ã‚ŒãŸè¡Œã‚’å‰Šé™¤ã€è¿½åŠ ã•ã‚ŒãŸè¡Œã‚’æŒ¿å…¥ã™ã‚‹
        
        # ç°¡å˜ã®ãŸã‚ã«ã€ä»Šå›žã¯ã€Œå…¨å‰Šé™¤ï¼†å…¨æŒ¿å…¥ã€ã§å®Ÿè£…
        # å®Ÿéš›ã«ã¯ã€IDã‚’åŸºã«update/insertã‚’ä½¿ã„åˆ†ã‘ã‚‹ã‹ã€upsertã‚’ä½¿ã†ã®ãŒè‰¯ã„
        # `supabase.table(table_name).upsert(data_to_upsert, on_conflict='ID').execute()`
        
        # ã“ã“ã§ã¯ã¾ãšã‚·ãƒ³ãƒ—ãƒ«ãªdelete().execute() & insert().execute()ã‚’è©¦ã™
        
        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’å…¨å‰Šé™¤
        st.sidebar.write(f"DEBUG: Deleting all existing data from table '{table_name}'...")
        delete_response = supabase.table(table_name).delete().neq('ID', -1).execute() # ID=-1ã¯å­˜åœ¨ã—ãªã„ã¨ä»®å®š
        # .execute()ã®æˆ»ã‚Šå€¤ã¯data, count, status_codeãªã©ã‚’å«ã‚€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        if delete_response.data is None: # Supabase client >= 2.0.0
             st.sidebar.write(f"DEBUG: Successfully cleared table '{table_name}'.")
        else: # Supabase client < 2.0.0 (old behavior, data might contain deleted rows)
            st.sidebar.write(f"DEBUG: Successfully cleared table '{table_name}'. Deleted {len(delete_response.data)} rows.")

        # æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’æŒ¿å…¥
        st.sidebar.write(f"DEBUG: Inserting {len(data_to_upsert)} rows into table '{table_name}'...")
        insert_response = supabase.table(table_name).insert(data_to_upsert).execute()
        
        if insert_response.data:
            st.cache_data.clear() # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¦ã€æ¬¡å›žã®èª­ã¿è¾¼ã¿ã§æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã•ã›ã‚‹
            st.sidebar.write(f"DEBUG: Data successfully written to Supabase table '{table_name}'.")
            return True
        else:
            st.error(f"Supabaseã¸ã®æ›¸ãè¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {insert_response}")
            st.sidebar.write(f"DEBUG: Supabase Write Error Response: {insert_response}")
            return False

    except Exception as e:
        st.error(f"Supabaseã¸ã®ãƒ‡ãƒ¼ã‚¿ã®æ›¸ãè¾¼ã¿ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        st.exception(e)
        st.sidebar.write(f"DEBUG: Unexpected Supabase Write Error: {e}")
        return False


# --- ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ ---

# ãƒ¦ãƒ¼ã‚¶ãƒ¼åã«å¿œã˜ãŸãƒ†ãƒ¼ãƒ–ãƒ«åã®è¨­å®š (usernameãŒNoneã®å ´åˆã¯ä¸€æ™‚çš„ãªãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)
# Supabaseã®ãƒ†ãƒ¼ãƒ–ãƒ«åã¯å°æ–‡å­—æŽ¨å¥¨ã€ãƒã‚¤ãƒ•ãƒ³ã§ã¯ãªãã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢æŽ¨å¥¨
# `vocab_`ã¨`test_results_`ã¨ã„ã†ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’ä»˜ã‘ã‚‹
current_vocab_table_name = f"vocab_{st.session_state.username.lower()}" if st.session_state.username else "vocab_default"
current_test_results_table_name = f"test_results_{st.session_state.username.lower()}" if st.session_state.username else "test_results_default"


# ãƒ¦ãƒ¼ã‚¶ãƒ¼åãŒè¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆï¼ˆãƒ­ã‚°ã‚¤ãƒ³å‰ï¼‰ã¯ã€ãƒ­ã‚°ã‚¤ãƒ³ãƒ•ã‚©ãƒ¼ãƒ ã‚’è¡¨ç¤º
if st.session_state.username is None:
    st.session_state.current_page = "Welcome" # å¿µã®ãŸã‚current_pageã‚’Welcomeã«è¨­å®š
    st.header("Welcome to ãƒ“ã‚¸ãƒã‚¹ç”¨èªžé›†ãƒ“ãƒ«ãƒ€ãƒ¼ï¼")
    st.write("ã“ã®ã‚¢ãƒ—ãƒªã¯ã€ã‚ãªãŸã®ãƒ“ã‚¸ãƒã‚¹ç”¨èªžå­¦ç¿’ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã™ã€‚")
    st.markdown("è©³ã—ã„ä½¿ã„æ–¹ã¯ã€ä»¥ä¸‹ã®ãƒšãƒ¼ã‚¸ã‚’ã”å‚ç…§ãã ã•ã„ã€‚")
    st.markdown("[ä½¿ã„æ–¹ã‚¬ã‚¤ãƒ‰ï¼ˆNotionï¼‰](https://www.notion.so/tacoms/285383207704802ca7cdddc3a7b8271f)")
    st.info("æœ€åˆã«ã‚ãªãŸã®åå‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    with st.form("username_form_welcome_fallback"): # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªãƒ•ã‚©ãƒ¼ãƒ ã‚­ãƒ¼
        input_username = st.text_input("ã‚ãªãŸã®åå‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        submit_username = st.form_submit_button("é€²ã‚€")
        if submit_username and input_username:
            st.session_state.username = input_username
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼åãŒè¨­å®šã•ã‚ŒãŸã®ã§ã€é–¢é€£ã™ã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«åã‚‚æ›´æ–°
            current_vocab_table_name = f"vocab_{st.session_state.username.lower()}"
            current_test_results_table_name = f"test_results_{st.session_state.username.lower()}"
            # æ–°ã—ã„ãƒ¦ãƒ¼ã‚¶ãƒ¼åã§ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã—ç›´ã™
            with st.spinner(f"{st.session_state.username}ã•ã‚“ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­..."):
                # Supabaseã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰
                st.session_state.df_vocab = load_data_from_supabase(current_vocab_table_name)
                st.session_state.df_test_results = load_data_from_supabase(current_test_results_table_name)
                st.session_state.vocab_data_loaded = True
            # ãƒ­ã‚°ã‚¤ãƒ³å¾Œã€ç”¨èªžé›†ã¸
            st.session_state.current_page = "ç”¨èªžé›†"
            st.rerun()
else: # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ã„ã‚‹å ´åˆ
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼åãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ãŒã€ãƒ‡ãƒ¼ã‚¿ãŒã¾ã ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãªã„å ´åˆã¯ãƒ­ãƒ¼ãƒ‰ã™ã‚‹
    if not st.session_state.vocab_data_loaded:
        with st.spinner(f"{st.session_state.username}ã•ã‚“ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­..."):
            # Supabaseã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰
            st.session_state.df_vocab = load_data_from_supabase(current_vocab_table_name)
            st.session_state.df_test_results = load_data_from_supabase(current_test_results_table_name)
            st.session_state.vocab_data_loaded = True
    
    # ã“ã“ã‹ã‚‰ã¯ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‹ã‚‰DataFrameã‚’å–å¾—ã—ã¦ä½¿ç”¨
    df_vocab = st.session_state.df_vocab
    df_test_results = st.session_state.df_test_results

    # --- å…±é€šã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
    st.sidebar.title(f"ã‚ˆã†ã“ãã€{st.session_state.username}ã•ã‚“ï¼")
    
    # ãƒšãƒ¼ã‚¸é¸æŠžãƒœã‚¿ãƒ³
    if st.sidebar.button("ðŸ“ ç”¨èªžé›†", key="nav_vocab_list"):
        go_to_page("ç”¨èªžé›†")
    if st.sidebar.button("ðŸ“Š ãƒ‡ãƒ¼ã‚¿ç®¡ç†", key="nav_data_management"):
        go_to_page("ãƒ‡ãƒ¼ã‚¿ç®¡ç†")
    if st.sidebar.button("ðŸ“ ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰", key="nav_test_mode"):
        go_to_page("ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰")
    if st.sidebar.button("ðŸ“ˆ ãƒ†ã‚¹ãƒˆçµæžœ", key="nav_test_results"):
        go_to_page("ãƒ†ã‚¹ãƒˆçµæžœ")
    st.sidebar.markdown("---")
    
    # æ–°è¦ç”¨èªžè¿½åŠ ãƒ•ã‚©ãƒ¼ãƒ  (ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«é…ç½®)
    st.sidebar.header("æ–°è¦ç”¨èªžã®è¿½åŠ ")
    with st.sidebar.form("add_term_form"):
        new_term = st.text_input("ç”¨èªž", key="sidebar_new_term")
        new_definition = st.text_area("èª¬æ˜Ž", key="sidebar_new_definition")
        new_example = st.text_area("ä¾‹æ–‡ (ä»»æ„)", key="sidebar_new_example")
        
        # ã‚«ãƒ†ã‚´ãƒªã®é¸æŠžè‚¢ã¯ã€df_vocabãŒç©ºã§ãªã‘ã‚Œã°ãã“ã‹ã‚‰å–å¾—
        categories = df_vocab['ã‚«ãƒ†ã‚´ãƒª (Category)'].dropna().unique().tolist() if not df_vocab.empty else []
        new_category = st.selectbox("ã‚«ãƒ†ã‚´ãƒª", [''] + categories + ['æ–°ã—ã„ã‚«ãƒ†ã‚´ãƒªã‚’ä½œæˆ'], key="sidebar_new_category")
        
        if new_category == 'æ–°ã—ã„ã‚«ãƒ†ã‚´ãƒªã‚’ä½œæˆ':
            new_category_text = st.text_input("æ–°ã—ã„ã‚«ãƒ†ã‚´ãƒªåã‚’å…¥åŠ›", key="sidebar_new_category_text")
            if new_category_text:
                new_category = new_category_text
        
        submitted = st.form_submit_button("ç”¨èªžã‚’è¿½åŠ ")
        if submitted:
            if new_term and new_definition and new_category and new_category != 'æ–°ã—ã„ã‚«ãƒ†ã‚´ãƒªã‚’ä½œæˆ': 
                next_id = (df_vocab['ID'].max() + 1) if not df_vocab.empty else 1
                new_row = pd.DataFrame([{
                    'ID': next_id,
                    'ç”¨èªž (Term)': new_term,
                    'èª¬æ˜Ž (Definition)': new_definition,
                    'ä¾‹æ–‡ (Example)': new_example,
                    'ã‚«ãƒ†ã‚´ãƒª (Category)': new_category,
                    'å­¦ç¿’é€²æ— (Progress)': 'Not Started'
                }])
                df_vocab = pd.concat([df_vocab, new_row], ignore_index=True)
                # Supabaseã«æ›¸ãè¾¼ã‚€
                if write_data_to_supabase(df_vocab, current_vocab_table_name):
                    st.success(f"ç”¨èªž '{new_term}' ã‚’è¿½åŠ ã—ã¾ã—ãŸï¼")
                    st.session_state.df_vocab = df_vocab # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‚‚æ›´æ–°
                    # å…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ã‚¯ãƒªã‚¢ (Streamlitã®ãƒã‚°å›žé¿ã®ãŸã‚rerun)
                    st.session_state.sidebar_new_term = ""
                    st.session_state.sidebar_new_definition = ""
                    st.session_state.sidebar_new_example = ""
                    st.rerun()
                else:
                    st.error("ç”¨èªžã®è¿½åŠ ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            else:
                st.error("ç”¨èªžã€èª¬æ˜Žã€æœ‰åŠ¹ãªã‚«ãƒ†ã‚´ãƒªã¯å¿…é ˆã§ã™ã€‚")
    
    st.sidebar.markdown("---")
    if st.sidebar.button("ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ", key="logout_button"):
        st.session_state.username = None
        st.session_state.current_page = "Welcome"
        st.session_state.vocab_data_loaded = False # ãƒ­ã‚°ã‚¢ã‚¦ãƒˆæ™‚ã«ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆ
        st.cache_data.clear() # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚‚ã‚¯ãƒªã‚¢
        st.session_state.df_vocab = pd.DataFrame(columns=VOCAB_HEADERS)
        st.session_state.df_test_results = pd.DataFrame(columns=TEST_RESULTS_HEADERS)
        st.rerun()

    # --- ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ ---
    if st.session_state.current_page == "ç”¨èªžé›†":
        st.header("ðŸ“ ç”¨èªžé›†")
        st.write("ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹ãƒ“ã‚¸ãƒã‚¹ç”¨èªžã‚’æ¤œç´¢ãƒ»é–²è¦§ã§ãã¾ã™ã€‚")

        if df_vocab.empty:
            st.info("ã¾ã ç”¨èªžãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰æ–°ã—ã„ç”¨èªžã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
        else:
            # æ¤œç´¢ã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã®UI
            col_search, col_category = st.columns([2, 1])
            with col_search:
                search_query = st.text_input("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ (ç”¨èªžã€èª¬æ˜Žã€ä¾‹æ–‡ã€ã‚«ãƒ†ã‚´ãƒª)", key="vocab_search_query")
            with col_category:
                categories = ['å…¨ã‚«ãƒ†ã‚´ãƒª'] + df_vocab['ã‚«ãƒ†ã‚´ãƒª (Category)'].dropna().unique().tolist()
                selected_category_filter = st.selectbox("ã‚«ãƒ†ã‚´ãƒªã§çµžã‚Šè¾¼ã¿", categories, key="vocab_category_filter")

            filtered_vocab = df_vocab.copy()

            # ã‚«ãƒ†ã‚´ãƒªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            if selected_category_filter != 'å…¨ã‚«ãƒ†ã‚´ãƒª':
                filtered_vocab = filtered_vocab[filtered_vocab['ã‚«ãƒ†ã‚´ãƒª (Category)'] == selected_category_filter]

            # æ–‡å­—æ¤œç´¢ (ã‚ã„ã¾ã„æ¤œç´¢)
            if search_query:
                search_cols = ['ç”¨èªž (Term)', 'èª¬æ˜Ž (Definition)', 'ä¾‹æ–‡ (Example)', 'ã‚«ãƒ†ã‚´ãƒª (Category)']
                filtered_vocab = filtered_vocab[
                    filtered_vocab[search_cols].astype(str).apply(
                        lambda x: x.str.contains(search_query, case=False, na=False)
                    ).any(axis=1)
                ]
            
            if filtered_vocab.empty:
                st.info("æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ç”¨èªžã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            else:
                st.dataframe(
                    filtered_vocab.set_index('ID'),
                    column_order=['ç”¨èªž (Term)', 'èª¬æ˜Ž (Definition)', 'ä¾‹æ–‡ (Example)', 'ã‚«ãƒ†ã‚´ãƒª (Category)', 'å­¦ç¿’é€²æ— (Progress)'],
                    use_container_width=True
                )

    elif st.session_state.current_page == "ãƒ‡ãƒ¼ã‚¿ç®¡ç†":
        st.header("ðŸ“Š ãƒ‡ãƒ¼ã‚¿ç®¡ç†")
        st.write("ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹ãƒ“ã‚¸ãƒã‚¹ç”¨èªžã®ä¸€è¦§ã‚’è¡¨ç¤ºãƒ»ç·¨é›†ã§ãã¾ã™ã€‚")
        
        if df_vocab.empty:
            st.info("ã¾ã ç”¨èªžãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰æ–°ã—ã„ç”¨èªžã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
            st.sidebar.write(f"DEBUG: df_vocab is empty. Columns: {df_vocab.columns.tolist()}")
        else:
            st.sidebar.write(f"DEBUG: df_vocab has {len(df_vocab)} rows.")
            edited_df = st.data_editor(
                df_vocab,
                column_config={
                    "ID": st.column_config.NumberColumn("ID", help="ç”¨èªžã®ID", width="small", disabled=True),
                    "ç”¨èªž (Term)": st.column_config.TextColumn("ç”¨èªž (Term)", help="ãƒ“ã‚¸ãƒã‚¹ç”¨èªž"),
                    "èª¬æ˜Ž (Definition)": st.column_config.TextColumn("èª¬æ˜Ž (Definition)", help="ç”¨èªžã®èª¬æ˜Ž"),
                    "ä¾‹æ–‡ (Example)": st.column_config.TextColumn("ä¾‹æ–‡ (Example)", help="ä½¿ç”¨ä¾‹"),
                    "ã‚«ãƒ†ã‚´ãƒª (Category)": st.column_config.SelectboxColumn("ã‚«ãƒ†ã‚´ãƒª (Category)", help="ç”¨èªžã®ã‚«ãƒ†ã‚´ãƒª",
                        options=df_vocab['ã‚«ãƒ†ã‚´ãƒª (Category)'].dropna().unique().tolist() + ['æ–°ã—ã„ã‚«ãƒ†ã‚´ãƒªã‚’ä½œæˆ'], required=True),
                    "å­¦ç¿’é€²æ— (Progress)": st.column_config.SelectboxColumn("å­¦ç¿’é€²æ— (Progress)", help="å­¦ç¿’ã®é€²æ—çŠ¶æ³",
                        options=['Not Started', 'Learning', 'Mastered'], required=True)
                },
                num_rows="dynamic",
                hide_index=True,
                use_container_width=True
            )
            
            if st.button("å¤‰æ›´ã‚’ä¿å­˜", key="save_data_management"):
                # æ–°ã—ã„ã‚«ãƒ†ã‚´ãƒªä½œæˆæ™‚ã®å‡¦ç†
                has_category_error = False
                for idx, row in edited_df.iterrows():
                    if row['ã‚«ãƒ†ã‚´ãƒª (Category)'] == 'æ–°ã—ã„ã‚«ãƒ†ã‚´ãƒªã‚’ä½œæˆ':
                        st.error(f"è¡Œ {idx+1}: 'æ–°ã—ã„ã‚«ãƒ†ã‚´ãƒªã‚’ä½œæˆ'ãŒé¸æŠžã•ã‚Œã¦ã„ã¾ã™ã€‚æœ‰åŠ¹ãªã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠžã¾ãŸã¯å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
                        has_category_error = True
                
                if has_category_error: # ã‚«ãƒ†ã‚´ãƒªã‚¨ãƒ©ãƒ¼ãŒã‚ã‚Œã°ã“ã“ã§å‡¦ç†ã‚’åœæ­¢
                    st.stop() 

                # å¿…é ˆã‚«ãƒ©ãƒ ã®ãƒã‚§ãƒƒã‚¯
                required_cols = ['ç”¨èªž (Term)', 'èª¬æ˜Ž (Definition)', 'ã‚«ãƒ†ã‚´ãƒª (Category)']
                if edited_df[required_cols].isnull().values.any() or (edited_df[required_cols] == '').any().any():
                    st.error("ç”¨èªžã€èª¬æ˜Žã€ã‚«ãƒ†ã‚´ãƒªã¯å¿…é ˆã§ã™ã€‚ç©ºæ¬„ãŒãªã„ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                    st.stop()
                else:
                    # 'ID'ãŒNaNã«ãªã£ã¦ã„ã‚‹æ–°è¦è¡Œã‚’ç‰¹å®šã—ã€IDã‚’ä»˜ä¸Ž
                    new_rows = edited_df[edited_df['ID'].isna()]
                    for idx, row in new_rows.iterrows():
                        next_id = (df_vocab['ID'].max() + 1) if not df_vocab.empty else 1
                        edited_df.loc[idx, 'ID'] = next_id
                    
                    # edited_dfã‚’df_vocabã«ä»£å…¥ã—ã€Supabaseã«æ›¸ãè¾¼ã‚€
                    df_vocab = edited_df.astype({'ID': 'Int64'})
                    if write_data_to_supabase(df_vocab, current_vocab_table_name):
                        st.success("å¤‰æ›´ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼")
                        st.session_state.df_vocab = df_vocab # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‚‚æ›´æ–°
                        st.rerun()
                    else:
                        st.error("å¤‰æ›´ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

        st.markdown("---")
        st.subheader("ãƒ‡ãƒ¼ã‚¿ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ / ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")

        # --- ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ ---
        st.markdown("##### ãƒ‡ãƒ¼ã‚¿ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
        csv_data = df_vocab.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            label="CSVã¨ã—ã¦ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ",
            data=csv_data,
            file_name=f"vocab_data_{st.session_state.username}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv",
            key="export_csv"
        )
        
        json_data = df_vocab.to_json(orient="records", force_ascii=False)
        st.download_button(
            label="JSONã¨ã—ã¦ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ",
            data=json_data,
            file_name=f"vocab_data_{st.session_state.username}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json",
            key="export_json"
        )

        # --- ã‚¤ãƒ³ãƒãƒ¼ãƒˆ ---
        st.markdown("##### ãƒ‡ãƒ¼ã‚¿ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ")
        uploaded_file = st.file_uploader("CSVã¾ãŸã¯JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["csv", "json"], key="import_file_uploader")

        if uploaded_file is not None:
            import_action = st.radio(
                "ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ–¹æ³•ã‚’é¸æŠž",
                ("æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ ", "æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ä¸Šæ›¸ã"),
                key="import_action_radio"
            )
            
            if st.button("ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’å®Ÿè¡Œ", key="execute_import"):
                try:
                    if uploaded_file.name.endswith('.csv'):
                        imported_df = pd.read_csv(uploaded_file)
                    elif uploaded_file.name.endswith('.json'):
                        imported_df = pd.read_json(uploaded_file)
                    else:
                        st.error("ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™ã€‚CSVã¾ãŸã¯JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
                        st.stop()
                    
                    # å¿…è¦ãªã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                    missing_cols = [col for col in VOCAB_HEADERS if col not in imported_df.columns]
                    if missing_cols:
                        st.warning(f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯ä»¥ä¸‹ã®å¿…é ˆã‚«ãƒ©ãƒ ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {', '.join(missing_cols)}ã€‚ã“ã‚Œã‚‰ã®ã‚«ãƒ©ãƒ ã¯ç©ºã¨ã—ã¦è¿½åŠ ã•ã‚Œã¾ã™ã€‚")
                        for col in missing_cols:
                            imported_df[col] = pd.NA
                    imported_df = imported_df[VOCAB_HEADERS]

                    if import_action == "æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ä¸Šæ›¸ã":
                        df_vocab = imported_df.copy()
                        # IDã¯å…¨ã¦æŒ¯ã‚Šç›´ã—
                        df_vocab['ID'] = range(1, len(df_vocab) + 1)
                        df_vocab['ID'] = df_vocab['ID'].astype('Int64')
                        st.warning("æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã¯å…¨ã¦ä¸Šæ›¸ãã•ã‚Œã¾ã™ã€‚")
                    else: # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ 
                        # æ—¢å­˜ã®IDã®æœ€å¤§å€¤ã‚’å–å¾—ã—ã€æ–°ã—ã„IDã‚’ä»˜ä¸Ž
                        max_id = df_vocab['ID'].max() if not df_vocab.empty else 0
                        
                        # ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã®IDã‚’æŒ¯ã‚Šç›´ã—ï¼ˆé‡è¤‡ã‚„NaNå¯¾ç­–ï¼‰
                        imported_df['ID'] = imported_df.apply(
                            lambda row: max_id + 1 + imported_df.index.get_loc(row.name) if pd.isna(row['ID']) or row['ID'] == 0 else row['ID'], axis=1
                        )
                        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã¨IDãŒé‡è¤‡ã—ãªã„ã‚ˆã†ã«èª¿æ•´
                        if not df_vocab.empty:
                            existing_ids = df_vocab['ID'].dropna().astype(int).tolist()
                            imported_df['ID'] = imported_df['ID'].apply(lambda x: x if x not in existing_ids else max_id + 1 + imported_df[imported_df['ID']==x].index[0])
                        
                        # æœ€çµ‚çš„ãªIDã‚’å†åº¦ä¸€æ„ã«èª¿æ•´ï¼ˆå¿µã®ãŸã‚ï¼‰
                        all_ids = list(df_vocab['ID'].dropna().astype(int)) if not df_vocab.empty else []
                        for i in range(len(imported_df)):
                            if imported_df.loc[i, 'ID'] in all_ids:
                                imported_df.loc[i, 'ID'] = max(all_ids) + 1
                            all_ids.append(int(imported_df.loc[i, 'ID']))
                        
                        df_vocab = pd.concat([df_vocab, imported_df], ignore_index=True)
                        df_vocab['ID'] = df_vocab['ID'].astype('Int64') # åž‹ã‚’åˆã‚ã›ã‚‹
                        st.info("æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ ã•ã‚Œã¾ã™ã€‚")
                    
                    df_vocab = df_vocab.drop_duplicates(subset=['ç”¨èªž (Term)', 'èª¬æ˜Ž (Definition)'], keep='first')
                    df_vocab = df_vocab.sort_values(by='ID').reset_index(drop=True)

                    if write_data_to_supabase(df_vocab, current_vocab_table_name):
                        st.success("ãƒ‡ãƒ¼ã‚¿ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«æˆåŠŸã—ã¾ã—ãŸï¼")
                        st.session_state.df_vocab = df_vocab # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‚‚æ›´æ–°
                        st.rerun()
                    else:
                        st.error("ãƒ‡ãƒ¼ã‚¿ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

                except Exception as e:
                    st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                    st.exception(e)
        
    elif st.session_state.current_page == "ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰":
        st.header("ðŸ“ ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰")
        st.write("ãƒ“ã‚¸ãƒã‚¹ç”¨èªžã®ç†è§£åº¦ã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã™ã€‚")

        if df_vocab.empty:
            st.info("ã¾ã ç”¨èªžãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰æ–°ã—ã„ç”¨èªžã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
            st.session_state.test_mode['active'] = False
        elif len(df_vocab) < 5:
            st.info("ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹ã™ã‚‹ã«ã¯ã€æœ€ä½Ž5ã¤ã®ç”¨èªžãŒå¿…è¦ã§ã™ã€‚")
            st.session_state.test_mode['active'] = False
        else:
            if not st.session_state.test_mode['active']:
                st.subheader("ãƒ†ã‚¹ãƒˆè¨­å®š")
                categories = df_vocab['ã‚«ãƒ†ã‚´ãƒª (Category)'].dropna().unique().tolist()
                
                st.session_state.test_mode['selected_category'] = st.selectbox(
                    "ãƒ†ã‚¹ãƒˆã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠž", ['å…¨ã‚«ãƒ†ã‚´ãƒª'] + categories, key="test_category_select")
                
                st.session_state.test_mode['question_count'] = st.slider(
