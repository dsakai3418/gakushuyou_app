import streamlit as st
import pandas as pd
import requests
import json
import os
import random
from datetime import datetime, date
import io

# --- Supabase æ¥ç¶šã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ ---
from st_supabase_connection import SupabaseConnection

# --- è¨­å®šé …ç›® ---
VOCAB_HEADERS = ['ID', 'ç”¨èª (Term)', 'èª¬æ˜ (Definition)', 'ä¾‹æ–‡ (Example)', 'ã‚«ãƒ†ã‚´ãƒª (Category)', 'å­¦ç¿’é€²æ— (Progress)']
TEST_RESULTS_HEADERS = ['Date', 'Category', 'TestType', 'Score', 'TotalQuestions', 'Details']

# --- Streamlit ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®é–‹å§‹ ---
st.set_page_config(layout="wide")
st.title("ãƒ“ã‚¸ãƒã‚¹ç”¨èªé›†ãƒ“ãƒ«ãƒ€ãƒ¼")

# st.session_state ã®åˆæœŸåŒ–
if 'username' not in st.session_state:
    st.session_state.username = None
if 'current_page' not in st.session_state:
    st.session_state.current_page = "ç”¨èªé›†"
if 'vocab_data_loaded' not in st.session_state:
    st.session_state.vocab_data_loaded = False
if 'test_mode' not in st.session_state:
    st.session_state.test_mode = {
        'active': False,
        'current_question_index': 0,
        'questions': [],
        'answers': [],
        'score': 0,
        'detailed_results': [],
        'selected_category': 'å…¨ã‚«ãƒ†ã‚´ãƒª',
        'question_count': 10,
        'test_type': 'term_to_def', # 'term_to_def' or 'example_to_term'
        'question_source': 'random_all' # 'random_all', 'learning_focus'
    }
if 'test_review_mode' not in st.session_state:
    st.session_state.test_review_mode = {
        'active': False,
        'review_index': 0,
        'results_to_review': []
    }
if 'df_vocab' not in st.session_state:
    st.session_state.df_vocab = pd.DataFrame(columns=VOCAB_HEADERS)
if 'df_test_results' not in st.session_state:
    st.session_state.df_test_results = pd.DataFrame(columns=TEST_RESULTS_HEADERS)


# --- Supabase æ¥ç¶šã®åˆæœŸåŒ– (st.secrets ã‹ã‚‰èªè¨¼æƒ…å ±ã‚’å–å¾—) ---
@st.cache_resource
def get_supabase_connection():
    url = st.secrets.get("SUPABASE_URL")
    key = st.secrets.get("SUPABASE_KEY")

    if not url or not key:
        st.error("Supabaseã®èªè¨¼æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚Streamlit Cloudã®Secretsã¾ãŸã¯.streamlit/secrets.tomlã«SUPABASE_URLã¨SUPABASE_KEYã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    return st.connection("supabase", type=SupabaseConnection, url=url, key=key)

supabase = get_supabase_connection()

# --- ãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã«è‡ªå‹•ã§ä½œæˆã™ã‚‹é–¢æ•° ---
# ã“ã®é–¢æ•°ã¯ã€Supabaseãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã« public.execute_sql é–¢æ•°ãŒä½œæˆã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’å‰æã¨ã—ã¾ã™ã€‚
def create_table_if_not_exists(table_name, headers, is_vocab_table=True):
    st.sidebar.write(f"DEBUG: Checking for table '{table_name}'...")
    try:
        # ãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª (ç°¡å˜ãªã‚¯ã‚¨ãƒªã‚’è©¦ã™)
        # å­˜åœ¨ã—ãªã„å ´åˆã€st-supabase-connectionã¯APIErrorã‚’ç™ºç”Ÿã•ã›ã‚‹
        supabase.table(table_name).select('ID').limit(0).execute()
        st.sidebar.write(f"DEBUG: Table '{table_name}' already exists.")
        return True
    except Exception as e:
        # ãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã€ã‚¨ãƒ©ãƒ¼ï¼ˆPGRST205ãªã©ï¼‰ãŒç™ºç”Ÿã™ã‚‹
        # APIErrorã‹ã©ã†ã‹ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ã€å­˜åœ¨ã—ãªã„å ´åˆã«ã®ã¿ä½œæˆå‡¦ç†ã«é€²ã‚€
        if isinstance(e, requests.exceptions.HTTPError) and e.response.status_code == 404: # å®Ÿéš›ã¯404ã§ã¯ãªãAPIErrorã®ã‚³ãƒ¼ãƒ‰ã‚’ãƒã‚§ãƒƒã‚¯
            st.sidebar.write(f"DEBUG: Table '{table_name}' does not exist (HTTP 404), creating it.")
        elif "PGRST205" in str(e): # PGRST205ã¯PostgRESTãŒãƒ†ãƒ¼ãƒ–ãƒ«ã‚’è¦‹ã¤ã‘ã‚‰ã‚Œãªã„ã‚¨ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰
             st.sidebar.write(f"DEBUG: Table '{table_name}' does not exist (PGRST205), creating it.")
        else:
            st.sidebar.write(f"DEBUG: Unknown error when checking table '{table_name}': {e}. Attempting to create.")
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆã‚¯ã‚¨ãƒª
        if is_vocab_table:
            columns_sql = ", ".join([f'"{h}" text NULL' for h in headers if h != 'ID'])
            create_query = f"""
            CREATE TABLE public."{table_name}" (
                "ID" bigint NOT NULL,
                {columns_sql},
                CONSTRAINT "{table_name}_pkey" PRIMARY KEY ("ID")
            );
            """
        else: # test_results_ table
            create_query = f"""
            CREATE TABLE public."{table_name}" (
                "Date" timestamp with time zone NULL,
                "Category" text NULL,
                "TestType" text NULL,
                "Score" bigint NULL,
                "TotalQuestions" bigint NULL,
                "Details" jsonb NULL
            );
            """
        
        try:
            # SQLã‚’å®Ÿè¡Œã—ã¦ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆ (RPCçµŒç”±)
            st.sidebar.write(f"DEBUG: Executing create table query for '{table_name}'...")
            supabase.rpc("execute_sql", {'sql_query': create_query}).execute()
            st.sidebar.write(f"DEBUG: Successfully created table '{table_name}'.")

            # RLSãƒãƒªã‚·ãƒ¼ã‚‚è‡ªå‹•ã§è¿½åŠ  (é–‹ç™ºç”¨ã€æœ¬ç•ªã§ã¯è¦‹ç›´ã—æ¨å¥¨)
            # å…¨å“¡ã«ã‚¢ã‚¯ã‚»ã‚¹ã‚’è¨±å¯ã™ã‚‹ãƒãƒªã‚·ãƒ¼
            rls_policy_query = f"""
            CREATE POLICY "Enable all access for anon users on {table_name}"
            ON public."{table_name}"
            FOR ALL
            TO anon
            USING (TRUE)
            WITH CHECK (TRUE);
            """
            st.sidebar.write(f"DEBUG: Executing RLS policy query for '{table_name}'...")
            supabase.rpc("execute_sql", {'sql_query': rls_policy_query}).execute()
            st.sidebar.write(f"DEBUG: RLS policy added for table '{table_name}'.")
            return True
        except Exception as create_e:
            st.error(f"ãƒ†ãƒ¼ãƒ–ãƒ« '{table_name}' ã®ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {create_e}")
            st.exception(create_e)
            st.sidebar.write(f"DEBUG: Table creation error: {create_e}")
            return False

# --- Supabaseã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹é–¢æ•° (GASç‰ˆã‹ã‚‰ã®å¤‰æ›´) ---
@st.cache_data(ttl=60)
def load_data_from_supabase(table_name):
    st.sidebar.write(f"DEBUG: Attempting to load data from Supabase table: {table_name}")
    try:
        # Supabaseã‹ã‚‰å…¨ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
        response = supabase.table(table_name).select("*").execute()
        
        if response.data:
            df = pd.DataFrame(response.data)
            st.sidebar.write(f"DEBUG: Successfully loaded {len(df)} rows from table '{table_name}'.")

            if table_name.startswith("vocab_"): # ç”¨èªã‚·ãƒ¼ãƒˆã®å ´åˆ
                # å¿…è¦ãªã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã—ãªã„å ´åˆã«ä½œæˆï¼ˆã‚¤ãƒ³ãƒãƒ¼ãƒˆæ™‚ã®ã‚¨ãƒ©ãƒ¼å›é¿ï¼‰
                for col in VOCAB_HEADERS:
                    if col not in df.columns:
                        df[col] = pd.NA
                df = df[VOCAB_HEADERS] # ã‚«ãƒ©ãƒ é †åºã‚’å›ºå®š
                
                df['ID'] = pd.to_numeric(df['ID'], errors='coerce').fillna(0).astype('Int64')
                df['å­¦ç¿’é€²æ— (Progress)'] = df['å­¦ç¿’é€²æ— (Progress)'].fillna('Not Started')
                df['ä¾‹æ–‡ (Example)'] = df['ä¾‹æ–‡ (Example)'].fillna('')
                df = df.dropna(subset=['ç”¨èª (Term)', 'èª¬æ˜ (Definition)'], how='all') # ä¸¡æ–¹NaNã®è¡Œã‚’å‰Šé™¤
                df = df.drop_duplicates(subset=['ç”¨èª (Term)', 'èª¬æ˜ (Definition)'], keep='first') # é‡è¤‡è¡Œã‚’å‰Šé™¤
                df = df.sort_values(by='ID').reset_index(drop=True)
                
            elif table_name.startswith("test_results_"): # ãƒ†ã‚¹ãƒˆçµæœã‚·ãƒ¼ãƒˆã®å ´åˆ
                for col in TEST_RESULTS_HEADERS:
                    if col not in df.columns:
                        df[col] = pd.NA
                df = df[TEST_RESULTS_HEADERS]

                if 'Date' in df.columns:
                    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')
                    df = df.dropna(subset=['Date'])
                    if not df.empty:
                        df = df.sort_values(by='Date', ascending=False).reset_index(drop=True)
                
                if 'Details' in df.columns and not df.empty:
                    def parse_json_safely(json_str):
                        if pd.isna(json_str) or not isinstance(json_str, str) or not json_str.strip():
                            return []
                        try:
                            # Supabaseã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã¯æ—¢ã«è¾æ›¸/ãƒªã‚¹ãƒˆã®å ´åˆã‚‚ã‚ã‚‹ãŸã‚ã€ç›´æ¥è¿”ã™
                            # æ–‡å­—åˆ—ã®å ´åˆã¯json.loadsã‚’è©¦ã¿ã‚‹
                            if isinstance(json_str, (dict, list)):
                                return json_str
                            return json.loads(json_str)
                        except (json.JSONDecodeError, TypeError):
                            st.warning(f"ãƒ†ã‚¹ãƒˆçµæœã®è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚’JSONã¨ã—ã¦ãƒ‘ãƒ¼ã‚¹ã§ãã¾ã›ã‚“ã§ã—ãŸ: {str(json_str)[:200]}...")
                            return []
                    df['Details'] = df['Details'].apply(parse_json_safely)
                else:
                    df['Details'] = [[] for _ in range(len(df))]
            
            return df
        else:
            st.sidebar.write(f"DEBUG: No data found in table '{table_name}'. Returning empty DataFrame.")
            return pd.DataFrame(columns=TEST_RESULTS_HEADERS if table_name.startswith("test_results_") else VOCAB_HEADERS)

    except Exception as e:
        st.error(f"Supabaseã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        st.exception(e)
        st.sidebar.write(f"DEBUG: Supabase Read Error: {e}")
        return pd.DataFrame(columns=TEST_RESULTS_HEADERS if table_name.startswith("test_results_") else VOCAB_HEADERS)


# --- Supabaseã«ãƒ‡ãƒ¼ã‚¿ã‚’æ›¸ãè¾¼ã‚€é–¢æ•° (GASç‰ˆã‹ã‚‰ã®å¤‰æ›´) ---
def write_data_to_supabase(df, table_name):
    try:
        data_to_upsert = df.to_dict(orient='records')
        
        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’å…¨å‰Šé™¤ (ID = -1 ã¯å­˜åœ¨ã—ãªã„ã¨ä»®å®šã—ã¦ã€å…¨è¡Œã‚’å¯¾è±¡)
        st.sidebar.write(f"DEBUG: Deleting all existing data from table '{table_name}'...")
        # delete().neq('ID', -1) ã¯ã€IDãŒ-1ã§ãªã„ã™ã¹ã¦ã®è¡Œã‚’å‰Šé™¤ã™ã‚‹ã¨ã„ã†æ„å›³ã€‚
        # Supabaseã®Pythonã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã§å…¨å‰Šé™¤ã™ã‚‹ã«ã¯ã€select('*').execute() ã§IDã‚’å–å¾—ã—ã¦ã‹ã‚‰å‰Šé™¤ã™ã‚‹ã‹ã€
        # ã‚ã‚‹ã„ã¯ RLS ã‚’è€ƒæ…®ã—ãªã„ãªã‚‰ .delete().gt('ID', 0) ãªã©ã§å…¨è¡Œå¯¾è±¡ã«ã™ã‚‹ã®ãŒç¢ºå®Ÿã€‚
        # ã“ã“ã§ã¯ä¸€ç•ªã‚·ãƒ³ãƒ—ãƒ«ãª .delete().neq('ID', -1).execute() ã§è¡ŒãŒè¿”ã•ã‚Œã‚‹ã“ã¨ã‚’æœŸå¾…ã™ã‚‹
        # .data ãŒ None ã§ãªã„ã“ã¨ã‚’ç¢ºèªã—ã¦ã€æˆåŠŸã‚’åˆ¤æ–­ã™ã‚‹
        delete_response = supabase.table(table_name).delete().neq('ID', -1).execute() 
        
        if delete_response.data is not None or delete_response.count >= 0: # å‰Šé™¤ãŒæ­£å¸¸ã«è¡Œã‚ã‚ŒãŸã¨åˆ¤æ–­
             st.sidebar.write(f"DEBUG: Successfully cleared table '{table_name}'. Deleted {delete_response.count} rows.")
        else:
            st.warning(f"DEBUG: Could not confirm clearing table '{table_name}'. Response: {delete_response}")


        # æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’æŒ¿å…¥
        st.sidebar.write(f"DEBUG: Inserting {len(data_to_upsert)} rows into table '{table_name}'...")
        insert_response = supabase.table(table_name).insert(data_to_upsert).execute()
        
        if insert_response.data: # æŒ¿å…¥ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãŒè¿”ã•ã‚Œã‚Œã°æˆåŠŸ
            st.cache_data.clear() # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¦ã€æ¬¡å›ã®èª­ã¿è¾¼ã¿ã§æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã•ã›ã‚‹
            st.sidebar.write(f"DEBUG: Data successfully written to Supabase table '{table_name}'.")
            return True
        else:
            st.error(f"Supabaseã¸ã®æ›¸ãè¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {insert_response}")
            st.sidebar.write(f"DEBUG: Supabase Write Error Response: {insert_response}")
            return False

    except Exception as e:
        st.error(f"Supabaseã¸ã®ãƒ‡ãƒ¼ã‚¿ã®æ›¸ãè¾¼ã¿ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        st.exception(e)
        st.sidebar.write(f"DEBUG: Unexpected Supabase Write Error: {e}")
        return False


# --- ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ ---

# ãƒ¦ãƒ¼ã‚¶ãƒ¼åã«å¿œã˜ãŸãƒ†ãƒ¼ãƒ–ãƒ«åã®è¨­å®š (usernameãŒNoneã®å ´åˆã¯ä¸€æ™‚çš„ãªãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)
current_vocab_table_name = f"vocab_{st.session_state.username.lower()}" if st.session_state.username else "vocab_default"
current_test_results_table_name = f"test_results_{st.session_state.username.lower()}" if st.session_state.username else "test_results_default"


# ãƒ¦ãƒ¼ã‚¶ãƒ¼åãŒè¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆï¼ˆãƒ­ã‚°ã‚¤ãƒ³å‰ï¼‰ã¯ã€ãƒ­ã‚°ã‚¤ãƒ³ãƒ•ã‚©ãƒ¼ãƒ ã‚’è¡¨ç¤º
if st.session_state.username is None:
    st.session_state.current_page = "Welcome"
    st.header("Welcome to ãƒ“ã‚¸ãƒã‚¹ç”¨èªé›†ãƒ“ãƒ«ãƒ€ãƒ¼ï¼")
    st.write("ã“ã®ã‚¢ãƒ—ãƒªã¯ã€ã‚ãªãŸã®ãƒ“ã‚¸ãƒã‚¹ç”¨èªå­¦ç¿’ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã™ã€‚")
    st.markdown("è©³ã—ã„ä½¿ã„æ–¹ã¯ã€ä»¥ä¸‹ã®ãƒšãƒ¼ã‚¸ã‚’ã”å‚ç…§ãã ã•ã„ã€‚")
    st.markdown("[ä½¿ã„æ–¹ã‚¬ã‚¤ãƒ‰ï¼ˆNotionï¼‰](https://www.notion.so/tacoms/285383207704802ca7cdddc3a7b8271f)")
    st.info("æœ€åˆã«ã‚ãªãŸã®åå‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    with st.form("username_form_welcome_fallback"):
        input_username = st.text_input("ã‚ãªãŸã®åå‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", key="login_username_input")
        submit_username = st.form_submit_button("é€²ã‚€")
        if submit_username and input_username:
            st.session_state.username = input_username
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼åãŒè¨­å®šã•ã‚ŒãŸã®ã§ã€é–¢é€£ã™ã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«åã‚‚æ›´æ–°
            current_vocab_table_name = f"vocab_{st.session_state.username.lower()}"
            current_test_results_table_name = f"test_results_{st.session_state.username.lower()}"
            
            with st.spinner(f"{st.session_state.username}ã•ã‚“ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ä¸­..."):
                # ãƒ†ãƒ¼ãƒ–ãƒ«è‡ªå‹•ç”Ÿæˆ
                if not create_table_if_not_exists(current_vocab_table_name, VOCAB_HEADERS, is_vocab_table=True):
                    st.error("ç”¨èªé›†ãƒ†ãƒ¼ãƒ–ãƒ«ã®æº–å‚™ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                    st.session_state.username = None # å¤±æ•—ã—ãŸã‚‰ãƒ­ã‚°ã‚¤ãƒ³ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«
                    st.rerun()
                if not create_table_if_not_exists(current_test_results_table_name, TEST_RESULTS_HEADERS, is_vocab_table=False):
                    st.error("ãƒ†ã‚¹ãƒˆçµæœãƒ†ãƒ¼ãƒ–ãƒ«ã®æº–å‚™ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                    st.session_state.username = None # å¤±æ•—ã—ãŸã‚‰ãƒ­ã‚°ã‚¤ãƒ³ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«
                    st.rerun()

                # æ–°ã—ã„ãƒ¦ãƒ¼ã‚¶ãƒ¼åã§ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã—ç›´ã™
                st.session_state.df_vocab = load_data_from_supabase(current_vocab_table_name)
                st.session_state.df_test_results = load_data_from_supabase(current_test_results_table_name)
                st.session_state.vocab_data_loaded = True
            # ãƒ­ã‚°ã‚¤ãƒ³å¾Œã€ç”¨èªé›†ã¸
            st.session_state.current_page = "ç”¨èªé›†"
            st.rerun()
else: # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ã„ã‚‹å ´åˆ
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼åãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ãŒã€ãƒ‡ãƒ¼ã‚¿ãŒã¾ã ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãªã„å ´åˆã¯ãƒ­ãƒ¼ãƒ‰ã™ã‚‹
    if not st.session_state.vocab_data_loaded:
        with st.spinner(f"{st.session_state.username}ã•ã‚“ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ä¸­..."):
            # ãƒ†ãƒ¼ãƒ–ãƒ«è‡ªå‹•ç”Ÿæˆ
            if not create_table_if_not_exists(current_vocab_table_name, VOCAB_HEADERS, is_vocab_table=True):
                st.error("ç”¨èªé›†ãƒ†ãƒ¼ãƒ–ãƒ«ã®æº–å‚™ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                st.session_state.username = None # å¤±æ•—ã—ãŸã‚‰ãƒ­ã‚°ã‚¤ãƒ³ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«
                st.rerun()
            if not create_table_if_not_exists(current_test_results_table_name, TEST_RESULTS_HEADERS, is_vocab_table=False):
                st.error("ãƒ†ã‚¹ãƒˆçµæœãƒ†ãƒ¼ãƒ–ãƒ«ã®æº–å‚™ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                st.session_state.username = None # å¤±æ•—ã—ãŸã‚‰ãƒ­ã‚°ã‚¤ãƒ³ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«
                st.rerun()

            # Supabaseã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰
            st.session_state.df_vocab = load_data_from_supabase(current_vocab_table_name)
            st.session_state.df_test_results = load_data_from_supabase(current_test_results_table_name)
            st.session_state.vocab_data_loaded = True
    
    # ã“ã“ã‹ã‚‰ã¯ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‹ã‚‰DataFrameã‚’å–å¾—ã—ã¦ä½¿ç”¨
    df_vocab = st.session_state.df_vocab
    df_test_results = st.session_state.df_test_results

    # --- å…±é€šã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
    st.sidebar.title(f"ã‚ˆã†ã“ãã€{st.session_state.username}ã•ã‚“ï¼")
    
    # ãƒšãƒ¼ã‚¸é¸æŠãƒœã‚¿ãƒ³
    if st.sidebar.button("ğŸ“ ç”¨èªé›†", key="nav_vocab_list"):
        go_to_page("ç”¨èªé›†")
    if st.sidebar.button("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ç®¡ç†", key="nav_data_management"):
        go_to_page("ãƒ‡ãƒ¼ã‚¿ç®¡ç†")
    if st.sidebar.button("ğŸ“ ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰", key="nav_test_mode"):
        go_to_page("ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰")
    if st.sidebar.button("ğŸ“ˆ ãƒ†ã‚¹ãƒˆçµæœ", key="nav_test_results"):
        go_to_page("ãƒ†ã‚¹ãƒˆçµæœ")
    st.sidebar.markdown("---")
    
    # æ–°è¦ç”¨èªè¿½åŠ ãƒ•ã‚©ãƒ¼ãƒ  (ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«é…ç½®)
    st.sidebar.header("æ–°è¦ç”¨èªã®è¿½åŠ ")
    with st.sidebar.form("add_term_form"):
        new_term = st.text_input("ç”¨èª", key="sidebar_new_term")
        new_definition = st.text_area("èª¬æ˜", key="sidebar_new_definition")
        new_example = st.text_area("ä¾‹æ–‡ (ä»»æ„)", key="sidebar_new_example")
        
        # ã‚«ãƒ†ã‚´ãƒªã®é¸æŠè‚¢ã¯ã€df_vocabãŒç©ºã§ãªã‘ã‚Œã°ãã“ã‹ã‚‰å–å¾—
        categories = df_vocab['ã‚«ãƒ†ã‚´ãƒª (Category)'].dropna().unique().tolist() if not df_vocab.empty else []
        new_category = st.selectbox("ã‚«ãƒ†ã‚´ãƒª", [''] + categories + ['æ–°ã—ã„ã‚«ãƒ†ã‚´ãƒªã‚’ä½œæˆ'], key="sidebar_new_category")
        
        if new_category == 'æ–°ã—ã„ã‚«ãƒ†ã‚´ãƒªã‚’ä½œæˆ':
            new_category_text = st.text_input("æ–°ã—ã„ã‚«ãƒ†ã‚´ãƒªåã‚’å…¥åŠ›", key="sidebar_new_category_text")
            if new_category_text:
                new_category = new_category_text
        
        submitted = st.form_submit_button("ç”¨èªã‚’è¿½åŠ ")
        if submitted:
            if new_term and new_definition and new_category and new_category != 'æ–°ã—ã„ã‚«ãƒ†ã‚´ãƒªã‚’ä½œæˆ': 
                next_id = (df_vocab['ID'].max() + 1) if not df_vocab.empty else 1
                new_row = pd.DataFrame([{
                    'ID': next_id,
                    'ç”¨èª (Term)': new_term,
                    'èª¬æ˜ (Definition)': new_definition,
                    'ä¾‹æ–‡ (Example)': new_example,
                    'ã‚«ãƒ†ã‚´ãƒª (Category)': new_category,
                    'å­¦ç¿’é€²æ— (Progress)': 'Not Started'
                }])
                df_vocab = pd.concat([df_vocab, new_row], ignore_index=True)
                # Supabaseã«æ›¸ãè¾¼ã‚€
                if write_data_to_supabase(df_vocab, current_vocab_table_name):
                    st.success(f"ç”¨èª '{new_term}' ã‚’è¿½åŠ ã—ã¾ã—ãŸï¼")
                    st.session_state.df_vocab = df_vocab # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‚‚æ›´æ–°
                    # å…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ã‚¯ãƒªã‚¢ (Streamlitã®ãƒã‚°å›é¿ã®ãŸã‚rerun)
                    st.session_state.sidebar_new_term = ""
                    st.session_state.sidebar_new_definition = ""
                    st.session_state.sidebar_new_example = ""
                    st.rerun()
                else:
                    st.error("ç”¨èªã®è¿½åŠ ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            else:
                st.error("ç”¨èªã€èª¬æ˜ã€æœ‰åŠ¹ãªã‚«ãƒ†ã‚´ãƒªã¯å¿…é ˆã§ã™ã€‚")
    
    st.sidebar.markdown("---")
    if st.sidebar.button("ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ", key="logout_button"):
        st.session_state.username = None
        st.session_state.current_page = "Welcome"
        st.session_state.vocab_data_loaded = False # ãƒ­ã‚°ã‚¢ã‚¦ãƒˆæ™‚ã«ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆ
        st.cache_data.clear() # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚‚ã‚¯ãƒªã‚¢
        st.session_state.df_vocab = pd.DataFrame(columns=VOCAB_HEADERS)
        st.session_state.df_test_results = pd.DataFrame(columns=TEST_RESULTS_HEADERS)
        st.rerun()

    # --- ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ ---
    if st.session_state.current_page == "ç”¨èªé›†":
        st.header("ğŸ“ ç”¨èªé›†")
        st.write("ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹ãƒ“ã‚¸ãƒã‚¹ç”¨èªã‚’æ¤œç´¢ãƒ»é–²è¦§ã§ãã¾ã™ã€‚")

        if df_vocab.empty:
            st.info("ã¾ã ç”¨èªãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰æ–°ã—ã„ç”¨èªã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
        else:
            # æ¤œç´¢ã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã®UI
            col_search, col_category = st.columns([2, 1])
            with col_search:
                search_query = st.text_input("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ (ç”¨èªã€èª¬æ˜ã€ä¾‹æ–‡ã€ã‚«ãƒ†ã‚´ãƒª)", key="vocab_search_query")
            with col_category:
                categories = ['å…¨ã‚«ãƒ†ã‚´ãƒª'] + df_vocab['ã‚«ãƒ†ã‚´ãƒª (Category)'].dropna().unique().tolist()
                selected_category_filter = st.selectbox("ã‚«ãƒ†ã‚´ãƒªã§çµã‚Šè¾¼ã¿", categories, key="vocab_category_filter")

            filtered_vocab = df_vocab.copy()

            # ã‚«ãƒ†ã‚´ãƒªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            if selected_category_filter != 'å…¨ã‚«ãƒ†ã‚´ãƒª':
                filtered_vocab = filtered_vocab[filtered_vocab['ã‚«ãƒ†ã‚´ãƒª (Category)'] == selected_category_filter]

            # æ–‡å­—æ¤œç´¢ (ã‚ã„ã¾ã„æ¤œç´¢)
            if search_query:
                search_cols = ['ç”¨èª (Term)', 'èª¬æ˜ (Definition)', 'ä¾‹æ–‡ (Example)', 'ã‚«ãƒ†ã‚´ãƒª (Category)']
                filtered_vocab = filtered_vocab[
                    filtered_vocab[search_cols].astype(str).apply(
                        lambda x: x.str.contains(search_query, case=False, na=False)
                    ).any(axis=1)
                ]
            
            if filtered_vocab.empty:
                st.info("æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ç”¨èªã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            else:
                st.dataframe(
                    filtered_vocab.set_index('ID'),
                    column_order=['ç”¨èª (Term)', 'èª¬æ˜ (Definition)', 'ä¾‹æ–‡ (Example)', 'ã‚«ãƒ†ã‚´ãƒª (Category)', 'å­¦ç¿’é€²æ— (Progress)'],
                    use_container_width=True
                )

    elif st.session_state.current_page == "ãƒ‡ãƒ¼ã‚¿ç®¡ç†":
        st.header("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ç®¡ç†")
        st.write("ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹ãƒ“ã‚¸ãƒã‚¹ç”¨èªã®ä¸€è¦§ã‚’è¡¨ç¤ºãƒ»ç·¨é›†ã§ãã¾ã™ã€‚")
        
        if df_vocab.empty:
            st.info("ã¾ã ç”¨èªãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰æ–°ã—ã„ç”¨èªã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
            st.sidebar.write(f"DEBUG: df_vocab is empty. Columns: {df_vocab.columns.tolist()}")
        else:
            st.sidebar.write(f"DEBUG: df_vocab has {len(df_vocab)} rows.")
            edited_df = st.data_editor(
                df_vocab,
                column_config={
                    "ID": st.column_config.NumberColumn("ID", help="ç”¨èªã®ID", width="small", disabled=True),
                    "ç”¨èª (Term)": st.column_config.TextColumn("ç”¨èª (Term)", help="ãƒ“ã‚¸ãƒã‚¹ç”¨èª"),
                    "èª¬æ˜ (Definition)": st.column_config.TextColumn("èª¬æ˜ (Definition)", help="ç”¨èªã®èª¬æ˜"),
                    "ä¾‹æ–‡ (Example)": st.column_config.TextColumn("ä¾‹æ–‡ (Example)", help="ä½¿ç”¨ä¾‹"),
                    "ã‚«ãƒ†ã‚´ãƒª (Category)": st.column_config.SelectboxColumn("ã‚«ãƒ†ã‚´ãƒª (Category)", help="ç”¨èªã®ã‚«ãƒ†ã‚´ãƒª",
                        options=df_vocab['ã‚«ãƒ†ã‚´ãƒª (Category)'].dropna().unique().tolist() + ['æ–°ã—ã„ã‚«ãƒ†ã‚´ãƒªã‚’ä½œæˆ'], required=True),
                    "å­¦ç¿’é€²æ— (Progress)": st.column_config.SelectboxColumn("å­¦ç¿’é€²æ— (Progress)", help="å­¦ç¿’ã®é€²æ—çŠ¶æ³",
                        options=['Not Started', 'Learning', 'Mastered'], required=True)
                },
                num_rows="dynamic",
                hide_index=True,
                use_container_width=True
            )
            
            if st.button("å¤‰æ›´ã‚’ä¿å­˜", key="save_data_management"):
                # æ–°ã—ã„ã‚«ãƒ†ã‚´ãƒªä½œæˆæ™‚ã®å‡¦ç†
                has_category_error = False
                for idx, row in edited_df.iterrows():
                    if row['ã‚«ãƒ†ã‚´ãƒª (Category)'] == 'æ–°ã—ã„ã‚«ãƒ†ã‚´ãƒªã‚’ä½œæˆ':
                        st.error(f"è¡Œ {idx+1}: 'æ–°ã—ã„ã‚«ãƒ†ã‚´ãƒªã‚’ä½œæˆ'ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã™ã€‚æœ‰åŠ¹ãªã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠã¾ãŸã¯å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
                        has_category_error = True
                
                if has_category_error: # ã‚«ãƒ†ã‚´ãƒªã‚¨ãƒ©ãƒ¼ãŒã‚ã‚Œã°ã“ã“ã§å‡¦ç†ã‚’åœæ­¢
                    st.stop() 

                # å¿…é ˆã‚«ãƒ©ãƒ ã®ãƒã‚§ãƒƒã‚¯
                required_cols = ['ç”¨èª (Term)', 'èª¬æ˜ (Definition)', 'ã‚«ãƒ†ã‚´ãƒª (Category)']
                if edited_df[required_cols].isnull().values.any() or (edited_df[required_cols] == '').any().any():
                    st.error("ç”¨èªã€èª¬æ˜ã€ã‚«ãƒ†ã‚´ãƒªã¯å¿…é ˆã§ã™ã€‚ç©ºæ¬„ãŒãªã„ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                    st.stop()
                else:
                    # 'ID'ãŒNaNã«ãªã£ã¦ã„ã‚‹æ–°è¦è¡Œã‚’ç‰¹å®šã—ã€IDã‚’ä»˜ä¸
                    new_rows = edited_df[edited_df['ID'].isna()]
                    for idx, row in new_rows.iterrows():
                        next_id = (df_vocab['ID'].max() + 1) if not df_vocab.empty else 1
                        edited_df.loc[idx, 'ID'] = next_id
                    
                    # edited_dfã‚’df_vocabã«ä»£å…¥ã—ã€Supabaseã«æ›¸ãè¾¼ã‚€
                    df_vocab = edited_df.astype({'ID': 'Int64'})
                    if write_data_to_supabase(df_vocab, current_vocab_table_name):
                        st.success("å¤‰æ›´ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼")
                        st.session_state.df_vocab = df_vocab # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‚‚æ›´æ–°
                        st.rerun()
                    else:
                        st.error("å¤‰æ›´ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

        st.markdown("---")
        st.subheader("ãƒ‡ãƒ¼ã‚¿ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ / ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")

        # --- ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ ---
        st.markdown("##### ãƒ‡ãƒ¼ã‚¿ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
        csv_data = df_vocab.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            label="CSVã¨ã—ã¦ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ",
            data=csv_data,
            file_name=f"vocab_data_{st.session_state.username}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv",
            key="export_csv"
        )
        
        json_data = df_vocab.to_json(orient="records", force_ascii=False)
        st.download_button(
            label="JSONã¨ã—ã¦ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ",
            data=json_data,
            file_name=f"vocab_data_{st.session_state.username}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json",
            key="export_json"
        )

        # --- ã‚¤ãƒ³ãƒãƒ¼ãƒˆ ---
        st.markdown("##### ãƒ‡ãƒ¼ã‚¿ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ")
        uploaded_file = st.file_uploader("CSVã¾ãŸã¯JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["csv", "json"], key="import_file_uploader")

        if uploaded_file is not None:
            import_action = st.radio(
                "ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ–¹æ³•ã‚’é¸æŠ",
                ("æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ ", "æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ä¸Šæ›¸ã"),
                key="import_action_radio"
            )
            
            if st.button("ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’å®Ÿè¡Œ", key="execute_import"):
                try:
                    if uploaded_file.name.endswith('.csv'):
                        imported_df = pd.read_csv(uploaded_file)
                    elif uploaded_file.name.endswith('.json'):
                        imported_df = pd.read_json(uploaded_file)
                    else:
                        st.error("ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™ã€‚CSVã¾ãŸã¯JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
                        st.stop()
                    
                    # å¿…è¦ãªã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                    missing_cols = [col for col in VOCAB_HEADERS if col not in imported_df.columns]
                    if missing_cols:
                        st.warning(f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯ä»¥ä¸‹ã®å¿…é ˆã‚«ãƒ©ãƒ ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {', '.join(missing_cols)}ã€‚ã“ã‚Œã‚‰ã®ã‚«ãƒ©ãƒ ã¯ç©ºã¨ã—ã¦è¿½åŠ ã•ã‚Œã¾ã™ã€‚")
                        for col in missing_cols:
                            imported_df[col] = pd.NA
                    imported_df = imported_df[VOCAB_HEADERS]

                    if import_action == "æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ä¸Šæ›¸ã":
                        df_vocab = imported_df.copy()
                        # IDã¯å…¨ã¦æŒ¯ã‚Šç›´ã—
                        df_vocab['ID'] = range(1, len(df_vocab) + 1)
                        df_vocab['ID'] = df_vocab['ID'].astype('Int64')
                        st.warning("æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã¯å…¨ã¦ä¸Šæ›¸ãã•ã‚Œã¾ã™ã€‚")
                    else: # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ 
                        # æ—¢å­˜ã®IDã®æœ€å¤§å€¤ã‚’å–å¾—ã—ã€æ–°ã—ã„IDã‚’ä»˜ä¸
                        max_id = df_vocab['ID'].max() if not df_vocab.empty else 0
                        
                        # ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã®IDã‚’æŒ¯ã‚Šç›´ã—ï¼ˆé‡è¤‡ã‚„NaNå¯¾ç­–ï¼‰
                        imported_df['ID'] = imported_df.apply(
                            lambda row: max_id + 1 + imported_df.index.get_loc(row.name) if pd.isna(row['ID']) or row['ID'] == 0 else row['ID'], axis=1
                        )
                        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã¨IDãŒé‡è¤‡ã—ãªã„ã‚ˆã†ã«èª¿æ•´
                        if not df_vocab.empty:
                            existing_ids = df_vocab['ID'].dropna().astype(int).tolist()
                            imported_df['ID'] = imported_df['ID'].apply(lambda x: x if x not in existing_ids else max_id + 1 + imported_df[imported_df['ID']==x].index[0])
                        
                        # æœ€çµ‚çš„ãªIDã‚’å†åº¦ä¸€æ„ã«èª¿æ•´ï¼ˆå¿µã®ãŸã‚ï¼‰
                        all_ids = list(df_vocab['ID'].dropna().astype(int)) if not df_vocab.empty else []
                        for i in range(len(imported_df)):
                            if imported_df.loc[i, 'ID'] in all_ids:
                                imported_df.loc[i, 'ID'] = max(all_ids) + 1
                            all_ids.append(int(imported_df.loc[i, 'ID']))
                        
                        df_vocab = pd.concat([df_vocab, imported_df], ignore_index=True)
                        df_vocab['ID'] = df_vocab['ID'].astype('Int64') # å‹ã‚’åˆã‚ã›ã‚‹
                        st.info("æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ ã•ã‚Œã¾ã™ã€‚")
                    
                    df_vocab = df_vocab.drop_duplicates(subset=['ç”¨èª (Term)', 'èª¬æ˜ (Definition)'], keep='first')
                    df_vocab = df_vocab.sort_values(by='ID').reset_index(drop=True)

                    if write_data_to_supabase(df_vocab, current_vocab_table_name):
                        st.success("ãƒ‡ãƒ¼ã‚¿ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«æˆåŠŸã—ã¾ã—ãŸï¼")
                        st.session_state.df_vocab = df_vocab # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‚‚æ›´æ–°
                        st.rerun()
                    else:
                        st.error("ãƒ‡ãƒ¼ã‚¿ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

                except Exception as e:
                    st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                    st.exception(e)
        
    elif st.session_state.current_page == "ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰":
        st.header("ğŸ“ ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰")
        st.write("ãƒ“ã‚¸ãƒã‚¹ç”¨èªã®ç†è§£åº¦ã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã™ã€‚")

        if df_vocab.empty:
            st.info("ã¾ã ç”¨èªãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰æ–°ã—ã„ç”¨èªã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
            st.session_state.test_mode['active'] = False
        elif len(df_vocab) < 5:
            st.info("ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹ã™ã‚‹ã«ã¯ã€æœ€ä½5ã¤ã®ç”¨èªãŒå¿…è¦ã§ã™ã€‚")
            st.session_state.test_mode['active'] = False
        else:
            if not st.session_state.test_mode['active']:
                st.subheader("ãƒ†ã‚¹ãƒˆè¨­å®š")
                categories = df_vocab['ã‚«ãƒ†ã‚´ãƒª (Category)'].dropna().unique().tolist()
                
                st.session_state.test_mode['selected_category'] = st.selectbox(
                    "ãƒ†ã‚¹ãƒˆã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠ", ['å…¨ã‚«ãƒ†ã‚´ãƒª'] + categories, key="test_category_select")
                
                st.session_state.test_mode['question_count'] = st.slider(
                    "å•é¡Œæ•°", min_value=5, max_value=len(df_vocab), value=min(10, len(df_vocab)), step=1, key="test_question_count_slider")
                
                st.session_state.test_mode['test_type'] = st.radio(
                    "ãƒ†ã‚¹ãƒˆå½¢å¼",
                    [('ç”¨èªã‹ã‚‰èª¬æ˜ã‚’é¸ã¶', 'term_to_def'),
                     ('ä¾‹æ–‡ã‹ã‚‰ç”¨èªã‚’é¸ã¶', 'example_to_term')],
                    format_func=lambda x: x[0], key="test_type_radio"
                )[1] # ã‚¿ãƒ—ãƒ«ã®2ç•ªç›®ã®è¦ç´ ï¼ˆã‚­ãƒ¼ï¼‰ã‚’å–å¾—
                
                st.session_state.test_mode['question_source'] = st.radio(
                    "å‡ºé¡Œå…ƒ",
                    [('ãƒ©ãƒ³ãƒ€ãƒ  (å…¨ç”¨èªã‹ã‚‰)', 'random_all'),
                     ('å­¦ç¿’ä¸è¶³ç”¨èªã‹ã‚‰å„ªå…ˆçš„ã«', 'learning_focus')],
                    format_func=lambda x: x[0], key="test_source_radio"
                )[1]

                if st.button("ãƒ†ã‚¹ãƒˆé–‹å§‹", key="start_test_button"):
                    start_new_test(df_vocab)
            else:
                run_test(df_vocab, current_test_results_table_name)

    elif st.session_state.current_page == "ãƒ†ã‚¹ãƒˆçµæœ":
        st.header("ğŸ“ˆ ãƒ†ã‚¹ãƒˆçµæœ")
        st.write("éå»ã®ãƒ†ã‚¹ãƒˆçµæœã‚’é–²è¦§ã§ãã¾ã™ã€‚")

        if df_test_results.empty:
            st.info("ã¾ã ãƒ†ã‚¹ãƒˆçµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã§å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã—ã‚‡ã†ï¼")
        else:
            # ãƒ†ã‚¹ãƒˆçµæœã®æ¦‚è¦è¡¨ç¤º
            st.subheader("ãƒ†ã‚¹ãƒˆçµæœä¸€è¦§")
            display_df_test_results = df_test_results.copy()
            # è¡¨ç¤ºç”¨ã®ã‚«ãƒ©ãƒ ã‚’é¸æŠã—ã€å¿…è¦ã§ã‚ã‚Œã°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
            display_df_test_results['Date'] = display_df_test_results['Date'].dt.strftime('%Y-%m-%d %H:%M')
            st.dataframe(
                display_df_test_results[['Date', 'Category', 'TestType', 'Score', 'TotalQuestions']],
                use_container_width=True,
                hide_index=True
            )

            # è©³ç´°ãƒ¬ãƒ“ãƒ¥ãƒ¼æ©Ÿèƒ½
            st.subheader("ãƒ†ã‚¹ãƒˆçµæœã®è©³ç´°ãƒ¬ãƒ“ãƒ¥ãƒ¼")
            if len(df_test_results) > 0:
                result_dates = df_test_results['Date'].dt.strftime('%Y-%m-%d %H:%M').tolist()
                selected_result_index = st.selectbox("ãƒ¬ãƒ“ãƒ¥ãƒ¼ã™ã‚‹ãƒ†ã‚¹ãƒˆçµæœã‚’é¸æŠ", range(len(result_dates)),
                                                     format_func=lambda x: result_dates[x], key="review_select_result")
                
                if st.button("ã“ã®ãƒ†ã‚¹ãƒˆçµæœã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼", key="start_review_button"):
                    st.session_state.test_review_mode['active'] = True
                    st.session_state.test_review_mode['review_index'] = 0
                    st.session_state.test_review_mode['results_to_review'] = df_test_results.loc[selected_result_index, 'Details']
                    go_to_page("ãƒ†ã‚¹ãƒˆçµæœ") # ç¾åœ¨ã®ãƒšãƒ¼ã‚¸ã‚’ãƒªãƒ­ãƒ¼ãƒ‰ã—ã¦ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤ºã‚’é–‹å§‹
            
            if st.session_state.test_review_mode['active']:
                review_current_question = st.session_state.test_review_mode['results_to_review'][st.session_state.test_review_mode['review_index']]
                
                st.markdown(f"#### å•é¡Œ {st.session_state.test_review_mode['review_index'] + 1} / {len(st.session_state.test_review_mode['results_to_review'])}")
                
                st.write(f"**å‡ºé¡Œ:** {review_current_question['question_text']}")
                st.write(f"**æ­£è§£:** {review_current_question['correct_answer']}")
                st.write(f"**ã‚ãªãŸã®å›ç­”:** {review_current_question['user_answer']}")
                
                if review_current_question['is_correct']:
                    st.success("âœ… æ­£è§£")
                else:
                    st.error("âŒ ä¸æ­£è§£")
                
                st.markdown("---")
                
                col1, col2 = st.columns(2)
                with col1:
                    if st.session_state.test_review_mode['review_index'] > 0:
                        if st.button("â¬…ï¸ å‰ã®å•é¡Œ", key="prev_review_question"):
                            st.session_state.test_review_mode['review_index'] -= 1
                            st.rerun()
                with col2:
                    if st.session_state.test_review_mode['review_index'] < len(st.session_state.test_review_mode['results_to_review']) - 1:
                        if st.button("æ¬¡ã®å•é¡Œ â¡ï¸", key="next_review_question"):
                            st.session_state.test_review_mode['review_index'] += 1
                            st.rerun()
                    else:
                        st.info("ã™ã¹ã¦ã®å•é¡Œã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
                        if st.button("ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’çµ‚äº†", key="end_review_mode"):
                            st.session_state.test_review_mode['active'] = False
                            st.rerun()

    else: # Welcomeãƒšãƒ¼ã‚¸ (ãƒ­ã‚°ã‚¤ãƒ³å‰)
        # ã“ã®ãƒ–ãƒ­ãƒƒã‚¯ã¯ã€ä¸Šè¨˜ã§æ—¢ã«ãƒ­ã‚°ã‚¤ãƒ³å‰å‡¦ç†ã¨ã—ã¦å®Ÿè£…æ¸ˆã¿ã®ãŸã‚ã€ã“ã“ã§ã¯ä½•ã‚‚ã—ãªã„
        pass


# --- ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰é–¢é€£é–¢æ•° ---
def start_new_test(df_vocab):
    test_settings = st.session_state.test_mode

    # é¸æŠã•ã‚ŒãŸã‚«ãƒ†ã‚´ãƒªã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    if test_settings['selected_category'] == 'å…¨ã‚«ãƒ†ã‚´ãƒª':
        available_vocab = df_vocab.copy()
    else:
        available_vocab = df_vocab[df_vocab['ã‚«ãƒ†ã‚´ãƒª (Category)'] == test_settings['selected_category']].copy()

    if available_vocab.empty or len(available_vocab) < test_settings['question_count']:
        st.error("é¸æŠã•ã‚ŒãŸæ¡ä»¶ã§ååˆ†ãªå•é¡Œã‚’ä½œæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã‚«ãƒ†ã‚´ãƒªã‚„å•é¡Œæ•°ã‚’è¦‹ç›´ã—ã¦ãã ã•ã„ã€‚")
        st.session_state.test_mode['active'] = False
        return

    # å‡ºé¡Œå…ƒã«åŸºã¥ããƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã¨é¸æŠ
    if test_settings['question_source'] == 'learning_focus':
        # 'Not Started' ã¨ 'Learning' ã®ç”¨èªã‚’å„ªå…ˆ
        focus_vocab = available_vocab[available_vocab['å­¦ç¿’é€²æ— (Progress)'].isin(['Not Started', 'Learning'])]
        if len(focus_vocab) >= test_settings['question_count']:
            selected_questions_df = focus_vocab.sample(n=test_settings['question_count'], random_state=random.randint(0, 10000))
        elif len(focus_vocab) > 0: # å„ªå…ˆç”¨èªãŒè¶³ã‚Šãªã‘ã‚Œã°ã€æ®‹ã‚Šã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«è£œå®Œ
            st.warning(f"å­¦ç¿’ä¸è¶³ç”¨èªãŒ{len(focus_vocab)}ä»¶ã—ã‹ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚æ®‹ã‚Šã¯ä»–ã®ç”¨èªã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠã—ã¾ã™ã€‚")
            remaining_count = test_settings['question_count'] - len(focus_vocab)
            other_vocab = available_vocab[~available_vocab.index.isin(focus_vocab.index)]
            selected_questions_df = pd.concat([
                focus_vocab,
                other_vocab.sample(n=remaining_count, random_state=random.randint(0, 10000))
            ])
        else: # å­¦ç¿’ä¸è¶³ç”¨èªãŒãªã„å ´åˆ
            st.info("å­¦ç¿’ä¸è¶³ç”¨èªãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸãŸã‚ã€å…¨ç”¨èªã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠã—ã¾ã™ã€‚")
            selected_questions_df = available_vocab.sample(n=test_settings['question_count'], random_state=random.randint(0, 10000))
    else: # 'random_all'
        selected_questions_df = available_vocab.sample(n=test_settings['question_count'], random_state=random.randint(0, 10000))

    questions = []
    for index, row in selected_questions_df.iterrows():
        correct_answer = ""
        question_text = ""
        if test_settings['test_type'] == 'term_to_def':
            question_text = f"ç”¨èª: **{row['ç”¨èª (Term)']}** ã®èª¬æ˜ã¨ã—ã¦æ­£ã—ã„ã‚‚ã®ã‚’é¸ã³ãªã•ã„ã€‚"
            correct_answer = row['èª¬æ˜ (Definition)']
            options_pool = available_vocab['èª¬æ˜ (Definition)'].tolist()
        elif test_settings['test_type'] == 'example_to_term':
            if pd.isna(row['ä¾‹æ–‡ (Example)']) or row['ä¾‹æ–‡ (Example)'] == '':
                # ä¾‹æ–‡ãŒãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ã‹ã€ä»–ã®å½¢å¼ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                continue 
            question_text = f"ä¾‹æ–‡: ã€Œ*{row['ä¾‹æ–‡ (Example)']}*ã€ ãŒç¤ºã™ç”¨èªã¨ã—ã¦æ­£ã—ã„ã‚‚ã®ã‚’é¸ã³ãªã•ã„ã€‚"
            correct_answer = row['ç”¨èª (Term)']
            options_pool = available_vocab['ç”¨èª (Term)'].tolist()
        
        # é¸æŠè‚¢ã‚’ä½œæˆ (æ­£è§£ã¨ç•°ãªã‚‹ãƒ€ãƒŸãƒ¼é¸æŠè‚¢ã‚’3ã¤è¿½åŠ )
        options = [correct_answer]
        dummy_options = [opt for opt in options_pool if opt != correct_answer]
        options.extend(random.sample(dummy_options, min(3, len(dummy_options))))
        random.shuffle(options)

        questions.append({
            'term_id': row['ID'],
            'term': row['ç”¨èª (Term)'],
            'definition': row['èª¬æ˜ (Definition)'],
            'example': row['ä¾‹æ–‡ (Example)'],
            'category': row['ã‚«ãƒ†ã‚´ãƒª (Category)'],
            'question_text': question_text,
            'correct_answer': correct_answer,
            'options': options
        })
    
    # é¸æŠè‚¢ãŒãªã„å•é¡ŒãŒã‚¹ã‚­ãƒƒãƒ—ã•ã‚ŒãŸå ´åˆã‚’è€ƒæ…®
    if not questions:
        st.error("é¸æŠã•ã‚ŒãŸæ¡ä»¶ã§æœ‰åŠ¹ãªå•é¡Œã‚’ä½œæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ä¾‹æ–‡ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„ç”¨èªãŒå«ã¾ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        st.session_state.test_mode['active'] = False
        return

    st.session_state.test_mode['active'] = True
    st.session_state.test_mode['current_question_index'] = 0
    st.session_state.test_mode['questions'] = questions
    st.session_state.test_mode['answers'] = [None] * len(questions)
    st.session_state.test_mode['score'] = 0
    st.session_state.test_mode['detailed_results'] = []
    st.rerun()


def run_test(df_vocab, current_test_results_table_name):
    test_mode = st.session_state.test_mode
    current_question = test_mode['questions'][test_mode['current_question_index']]

    st.subheader(f"å•é¡Œ {test_mode['current_question_index'] + 1} / {len(test_mode['questions'])}")
    st.markdown(current_question['question_text'])

    user_answer = st.radio(
        "å›ç­”ã‚’é¸æŠã—ã¦ãã ã•ã„:",
        current_question['options'],
        key=f"q_{test_mode['current_question_index']}"
    )
    
    st.session_state.test_mode['answers'][test_mode['current_question_index']] = user_answer

    col1, col2 = st.columns(2)
    with col1:
        if st.button("å‰ã®å•é¡Œ", key="prev_q"):
            if test_mode['current_question_index'] > 0:
                test_mode['current_question_index'] -= 1
                st.rerun()
    with col2:
        if st.button("æ¬¡ã®å•é¡Œ", key="next_q"):
            if test_mode['current_question_index'] < len(test_mode['questions']) - 1:
                test_mode['current_question_index'] += 1
                st.rerun()
            else: # æœ€çµ‚å•é¡Œã®æ¬¡ã‚’æŠ¼ã—ãŸã¨ã
                end_test(df_vocab, current_test_results_table_name)


def end_test(df_vocab, current_test_results_table_name):
    test_mode = st.session_state.test_mode
    total_score = 0
    detailed_results = []

    for i, question in enumerate(test_mode['questions']):
        user_answer = test_mode['answers'][i]
        is_correct = (user_answer == question['correct_answer'])
        
        if is_correct:
            total_score += 1
            # å­¦ç¿’é€²æ—ã‚’æ›´æ–°ï¼ˆæ­£è§£ã—ãŸã‚‰Masteredã¸å‘ã‹ã†ï¼‰
            vocab_idx = df_vocab[df_vocab['ID'] == question['term_id']].index
            if not vocab_idx.empty:
                current_progress = df_vocab.loc[vocab_idx[0], 'å­¦ç¿’é€²æ— (Progress)']
                if current_progress == 'Not Started':
                    df_vocab.loc[vocab_idx[0], 'å­¦ç¿’é€²æ— (Progress)'] = 'Learning'
                elif current_progress == 'Learning':
                    df_vocab.loc[vocab_idx[0], 'å­¦ç¿’é€²æ— (Progress)'] = 'Mastered'
        else:
            # ä¸æ­£è§£ãªã‚‰å­¦ç¿’é€²æ—ã‚’Learningã«æˆ»ã™
            vocab_idx = df_vocab[df_vocab['ID'] == question['term_id']].index
            if not vocab_idx.empty:
                df_vocab.loc[vocab_idx[0], 'å­¦ç¿’é€²æ— (Progress)'] = 'Learning'

        detailed_results.append({
            'term_id': question['term_id'],
            'term': question['term'],
            'definition': question['definition'],
            'question_text': question['question_text'],
            'correct_answer': question['correct_answer'],
            'user_answer': user_answer,
            'is_correct': is_correct
        })

    st.session_state.df_vocab = df_vocab # æ›´æ–°ã•ã‚ŒãŸdf_vocabã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜
    write_data_to_supabase(df_vocab, current_vocab_table_name) # ç”¨èªé›†ãƒ‡ãƒ¼ã‚¿ã‚‚æ›´æ–°

    # ãƒ†ã‚¹ãƒˆçµæœã‚’ä¿å­˜
    new_test_result = pd.DataFrame([{
        'Date': datetime.now(),
        'Category': test_mode['selected_category'],
        'TestType': test_mode['test_type'],
        'Score': total_score,
        'TotalQuestions': len(test_mode['questions']),
        'Details': detailed_results # ã“ã“ãŒJSONBã«ãªã‚‹éƒ¨åˆ†
    }])
    st.session_state.df_test_results = pd.concat([st.session_state.df_test_results, new_test_result], ignore_index=True)
    write_data_to_supabase(st.session_state.df_test_results, current_test_results_table_name)

    st.subheader("ãƒ†ã‚¹ãƒˆçµ‚äº†ï¼")
    st.success(f"ã‚ãªãŸã®ã‚¹ã‚³ã‚¢: {total_score} / {len(test_mode['questions'])}")
    
    if st.button("è©³ç´°çµæœã‚’è¦‹ã‚‹", key="view_detailed_results"):
        st.session_state.test_review_mode['active'] = True
        st.session_state.test_review_mode['review_index'] = 0
        st.session_state.test_review_mode['results_to_review'] = detailed_results
        st.session_state.test_mode['active'] = False # ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã‚’çµ‚äº†
        go_to_page("ãƒ†ã‚¹ãƒˆçµæœ") # ãƒ†ã‚¹ãƒˆçµæœãƒšãƒ¼ã‚¸ã«é·ç§»

    if st.button("æ–°ã—ã„ãƒ†ã‚¹ãƒˆã‚’å§‹ã‚ã‚‹", key="start_new_test_after_finish"):
        st.session_state.test_mode['active'] = False
        st.rerun()

    if st.button("ç”¨èªé›†ã«æˆ»ã‚‹", key="back_to_vocab_list_after_finish"):
        st.session_state.test_mode['active'] = False
        go_to_page("ç”¨èªé›†")
